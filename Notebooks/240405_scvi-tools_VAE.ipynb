{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to understand the scVI model\n",
    "    Developed by: Christian Eger\n",
    "    Würzburg Institute for Systems Immunology, Faculty of Medicine, Julius-Maximilian-Universität Würzburg\n",
    "    Created: 240328\n",
    "    Latest version: 240408"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ceger/miniforge3/envs/pytorch-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ceger/miniforge3/envs/pytorch-env/lib/python3.10/site-packages/flax/struct.py:132: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
      "  jax.tree_util.register_keypaths(data_clz, keypaths)\n",
      "/home/ceger/miniforge3/envs/pytorch-env/lib/python3.10/site-packages/flax/struct.py:132: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
      "  jax.tree_util.register_keypaths(data_clz, keypaths)\n",
      "/home/ceger/miniforge3/envs/pytorch-env/lib/python3.10/site-packages/flax/struct.py:132: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
      "  jax.tree_util.register_keypaths(data_clz, keypaths)\n"
     ]
    }
   ],
   "source": [
    "import scvi\n",
    "import scanpy as sc\n",
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 97573 × 27208\n",
       "    obs: 'sex', 'age', 'ethnicity', 'PaCO2', 'donor', 'infection', 'disease', 'SMK', 'illumina_stimunr', 'bd_rhapsody', 'n_genes', 'doublet_scores', 'predicted_doublets', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'percent_mt2', 'n_counts', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'condition', 'sample_group', 'IAV_score', 'group', 'Viral_score', 'cell_type', 'cell_states', 'leiden', 'cell_compartment', 'seed_labels', '_scvi_batch', '_scvi_labels', 'C_scANVI'\n",
       "    var: 'mt', 'ribo'\n",
       "    obsm: 'X_scANVI', 'X_scVI', 'X_umap'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata = sc.read_h5ad(\n",
    "    '../data/Marburg_cell_states_locked_scANVI_ctl230901.raw.h5ad'\n",
    ")\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.layers['counts'] = adata.X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.highly_variable_genes(\n",
    "    adata=adata,\n",
    "    n_top_genes=3000,\n",
    "    layer='counts',\n",
    "    flavor='seurat_v3',\n",
    "    batch_key='batch'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scVI model preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scvi.model.SCVI.setup_anndata(\n",
    "    adata=adata,\n",
    "    layer='counts',\n",
    "    batch_key='donor',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = scvi.model.SCVI(\n",
    "    adata=adata,\n",
    "    n_latent=50,\n",
    "    n_hidden=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA RTX 6000 Ada Generation') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/82:   1%|          | 1/82 [00:05<06:44,  5.00s/it, v_num=1, train_loss_step=1.95e+4, train_loss_epoch=2.62e+4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ceger/miniforge3/envs/pytorch-env/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:53: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scVI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (z_encoder): Encoder(\n",
       "    (encoder): FCLayers(\n",
       "      (fc_layers): Sequential(\n",
       "        (Layer 0): Sequential(\n",
       "          (0): Linear(in_features=27208, out_features=3, bias=True)\n",
       "          (1): BatchNorm1d(3, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): None\n",
       "          (3): ReLU()\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mean_encoder): Linear(in_features=3, out_features=50, bias=True)\n",
       "    (var_encoder): Linear(in_features=3, out_features=50, bias=True)\n",
       "  )\n",
       "  (l_encoder): Encoder(\n",
       "    (encoder): FCLayers(\n",
       "      (fc_layers): Sequential(\n",
       "        (Layer 0): Sequential(\n",
       "          (0): Linear(in_features=27208, out_features=3, bias=True)\n",
       "          (1): BatchNorm1d(3, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): None\n",
       "          (3): ReLU()\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mean_encoder): Linear(in_features=3, out_features=1, bias=True)\n",
       "    (var_encoder): Linear(in_features=3, out_features=1, bias=True)\n",
       "  )\n",
       "  (decoder): DecoderSCVI(\n",
       "    (px_decoder): FCLayers(\n",
       "      (fc_layers): Sequential(\n",
       "        (Layer 0): Sequential(\n",
       "          (0): Linear(in_features=62, out_features=3, bias=True)\n",
       "          (1): BatchNorm1d(3, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): None\n",
       "          (3): ReLU()\n",
       "          (4): None\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (px_scale_decoder): Sequential(\n",
       "      (0): Linear(in_features=3, out_features=27208, bias=True)\n",
       "      (1): Softmax(dim=-1)\n",
       "    )\n",
       "    (px_r_decoder): Linear(in_features=3, out_features=27208, bias=True)\n",
       "    (px_dropout_decoder): Linear(in_features=3, out_features=27208, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scVI class rebuilding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FC Layer Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scVI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (Layer 0): Sequential(\n",
       "    (0): Linear(in_features=27208, out_features=3, bias=True)\n",
       "    (1): BatchNorm1d(3, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    (2): None\n",
       "    (3): ReLU()\n",
       "    (4): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.module.z_encoder.encoder.fc_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rebuilt model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCLayers(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                in_features=in_features,\n",
    "                out_features=out_features,\n",
    "                bias=True,\n",
    "            ),\n",
    "            nn.BatchNorm1d(\n",
    "                3,\n",
    "                eps=0.001,\n",
    "                momentum=0.01,\n",
    "                affine=True,\n",
    "                track_running_stats=True\n",
    "            ),\n",
    "            None,\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(\n",
    "                p=0.1,\n",
    "                inplace=False,\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc_layers(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCLayers(\n",
       "  (fc_layers): Sequential(\n",
       "    (0): Linear(in_features=27208, out_features=3, bias=True)\n",
       "    (1): BatchNorm1d(3, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    (2): None\n",
       "    (3): ReLU()\n",
       "    (4): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCLayers(\n",
    "    in_features=27208,\n",
    "    out_features=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scVI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (encoder): FCLayers(\n",
       "    (fc_layers): Sequential(\n",
       "      (Layer 0): Sequential(\n",
       "        (0): Linear(in_features=27208, out_features=3, bias=True)\n",
       "        (1): BatchNorm1d(3, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): None\n",
       "        (3): ReLU()\n",
       "        (4): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mean_encoder): Linear(in_features=3, out_features=50, bias=True)\n",
       "  (var_encoder): Linear(in_features=3, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.module.z_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (encoder): FCLayers(\n",
       "    (fc_layers): Sequential(\n",
       "      (Layer 0): Sequential(\n",
       "        (0): Linear(in_features=27208, out_features=3, bias=True)\n",
       "        (1): BatchNorm1d(3, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): None\n",
       "        (3): ReLU()\n",
       "        (4): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mean_encoder): Linear(in_features=3, out_features=1, bias=True)\n",
       "  (var_encoder): Linear(in_features=3, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.module.l_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rebuilt model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Normal\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            fc_in,\n",
    "            fc_out,\n",
    "            n_hidden,\n",
    "            n_output,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.fc_in = fc_in\n",
    "        self.fc_out = fc_out\n",
    "        self.encoder = FCLayers(\n",
    "            in_features=fc_in,\n",
    "            out_features=fc_out,\n",
    "        )\n",
    "        self.mean_encoder = nn.Linear(\n",
    "            in_features=n_hidden,\n",
    "            out_features=n_output,\n",
    "        )\n",
    "        self.var_encoder = nn.Linear(\n",
    "            in_features=n_hidden,\n",
    "            out_features=n_output,\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        q = self.encoder(x)\n",
    "        q_m = self.mean_encoder(q)\n",
    "        q_v = torch.exp(self.var_encoder(q)) + 1e-4\n",
    "        dist = Normal(q_m, q_v.sqrt())\n",
    "        latent = dist.rsample()\n",
    "        return q_m, q_v, latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (encoder): FCLayers(\n",
       "    (fc_layers): Sequential(\n",
       "      (0): Linear(in_features=27208, out_features=3, bias=True)\n",
       "      (1): BatchNorm1d(3, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): None\n",
       "      (3): ReLU()\n",
       "      (4): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (mean_encoder): Linear(in_features=3, out_features=50, bias=True)\n",
       "  (var_encoder): Linear(in_features=3, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Encoder(\n",
    "    fc_in=27208,\n",
    "    fc_out=3,\n",
    "    n_hidden=3,\n",
    "    n_output=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (encoder): FCLayers(\n",
       "    (fc_layers): Sequential(\n",
       "      (0): Linear(in_features=27208, out_features=3, bias=True)\n",
       "      (1): BatchNorm1d(3, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): None\n",
       "      (3): ReLU()\n",
       "      (4): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (mean_encoder): Linear(in_features=3, out_features=1, bias=True)\n",
       "  (var_encoder): Linear(in_features=3, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Encoder(\n",
    "    fc_in=27208,\n",
    "    fc_out=3,\n",
    "    n_hidden=3,\n",
    "    n_output=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecoderSCVI class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scVI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderSCVI(\n",
       "  (px_decoder): FCLayers(\n",
       "    (fc_layers): Sequential(\n",
       "      (Layer 0): Sequential(\n",
       "        (0): Linear(in_features=62, out_features=3, bias=True)\n",
       "        (1): BatchNorm1d(3, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): None\n",
       "        (3): ReLU()\n",
       "        (4): None\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (px_scale_decoder): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=27208, bias=True)\n",
       "    (1): Softmax(dim=-1)\n",
       "  )\n",
       "  (px_r_decoder): Linear(in_features=3, out_features=27208, bias=True)\n",
       "  (px_dropout_decoder): Linear(in_features=3, out_features=27208, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.module.decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rebuilt model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderSCVI(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            fc_in,\n",
    "            fc_out,\n",
    "            decoder_in,\n",
    "            decoder_out,\n",
    "            dispersion = 'gene'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.fc_in = fc_in\n",
    "        self.fc_out = fc_out\n",
    "        self.decoder_in = decoder_in\n",
    "        self.decoder_out = decoder_out\n",
    "        self.px_decoder = FCLayers(\n",
    "            in_features=fc_in,\n",
    "            out_features=fc_out,\n",
    "        )\n",
    "        self.px_scale_decoder = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                in_features=decoder_in,\n",
    "                out_features=decoder_out,\n",
    "            ),\n",
    "            nn.Softmax(dim=1)\n",
    "                    )\n",
    "        self.px_r_decoder = nn.Linear(\n",
    "            in_features=decoder_in,\n",
    "            out_features=decoder_out,\n",
    "        )\n",
    "        self.px_dropout_decoder = nn.Linear(\n",
    "            in_features=decoder_in,\n",
    "            out_features=decoder_out,\n",
    "        )\n",
    "\n",
    "    def forward(self, x, library):\n",
    "        px = self.px_decoder(x)\n",
    "        px_scale = self.px_scale_decoder(px)\n",
    "        px_dropout = self.px_dropout_decoder(px)\n",
    "        px_rate = torch.exp(library) * px_scale\n",
    "        px_r = None\n",
    "        return px_scale, px_r, px_rate, px_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderSCVI(\n",
       "  (px_decoder): FCLayers(\n",
       "    (fc_layers): Sequential(\n",
       "      (0): Linear(in_features=62, out_features=3, bias=True)\n",
       "      (1): BatchNorm1d(3, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): None\n",
       "      (3): ReLU()\n",
       "      (4): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (px_scale_decoder): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=27208, bias=True)\n",
       "    (1): Softmax(dim=1)\n",
       "  )\n",
       "  (px_r_decoder): Linear(in_features=3, out_features=27208, bias=True)\n",
       "  (px_dropout_decoder): Linear(in_features=3, out_features=27208, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecoderSCVI(\n",
    "    fc_in=62,\n",
    "    fc_out=3,\n",
    "    decoder_in=3,\n",
    "    decoder_out=27208,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scVI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (z_encoder): Encoder(\n",
       "    (encoder): FCLayers(\n",
       "      (fc_layers): Sequential(\n",
       "        (Layer 0): Sequential(\n",
       "          (0): Linear(in_features=27208, out_features=3, bias=True)\n",
       "          (1): BatchNorm1d(3, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): None\n",
       "          (3): ReLU()\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mean_encoder): Linear(in_features=3, out_features=50, bias=True)\n",
       "    (var_encoder): Linear(in_features=3, out_features=50, bias=True)\n",
       "  )\n",
       "  (l_encoder): Encoder(\n",
       "    (encoder): FCLayers(\n",
       "      (fc_layers): Sequential(\n",
       "        (Layer 0): Sequential(\n",
       "          (0): Linear(in_features=27208, out_features=3, bias=True)\n",
       "          (1): BatchNorm1d(3, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): None\n",
       "          (3): ReLU()\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mean_encoder): Linear(in_features=3, out_features=1, bias=True)\n",
       "    (var_encoder): Linear(in_features=3, out_features=1, bias=True)\n",
       "  )\n",
       "  (decoder): DecoderSCVI(\n",
       "    (px_decoder): FCLayers(\n",
       "      (fc_layers): Sequential(\n",
       "        (Layer 0): Sequential(\n",
       "          (0): Linear(in_features=62, out_features=3, bias=True)\n",
       "          (1): BatchNorm1d(3, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): None\n",
       "          (3): ReLU()\n",
       "          (4): None\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (px_scale_decoder): Sequential(\n",
       "      (0): Linear(in_features=3, out_features=27208, bias=True)\n",
       "      (1): Softmax(dim=-1)\n",
       "    )\n",
       "    (px_r_decoder): Linear(in_features=3, out_features=27208, bias=True)\n",
       "    (px_dropout_decoder): Linear(in_features=3, out_features=27208, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rebuilt model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            z_enc_fc_in,\n",
    "            z_enc_fc_out,\n",
    "            z_n_hidden,\n",
    "            z_n_output,\n",
    "            l_enc_fc_in,\n",
    "            l_enc_fc_out,\n",
    "            l_n_hidden,\n",
    "            l_n_output,\n",
    "            decoder_fc_in,\n",
    "            decoder_fc_out,\n",
    "            decoder_in,\n",
    "            decoder_out,\n",
    "    ):\n",
    "        self.z_enc_fc_in = z_enc_fc_in\n",
    "        self.z_enc_fc_out = z_enc_fc_out\n",
    "        self.z_enc_fc_bias = True\n",
    "        self.z_n_hidden = z_n_hidden\n",
    "        self.z_n_output = z_n_output\n",
    "        self.l_enc_fc_in = l_enc_fc_in\n",
    "        self.l_enc_fc_out = l_enc_fc_out\n",
    "        self.l_enc_fc_bias = True\n",
    "        self.l_n_hidden = l_n_hidden\n",
    "        self.l_n_output = l_n_output\n",
    "        self.decoder_fc_in = decoder_fc_in\n",
    "        self.decoder_fc_out = decoder_fc_out\n",
    "        self.decoder_fc_bias = True\n",
    "        self.decoder_in = decoder_in\n",
    "        self.decoder_out = decoder_out\n",
    "        self.decoder_bias = True\n",
    "        super().__init__()\n",
    "        self.z_encoder = Encoder(\n",
    "            fc_in=z_enc_fc_in,\n",
    "            fc_out=z_enc_fc_out,\n",
    "            n_hidden=z_n_hidden,\n",
    "            n_output=z_n_output,\n",
    "        )\n",
    "        self.l_encoder = Encoder(\n",
    "            fc_in=l_enc_fc_in,\n",
    "            fc_out=l_enc_fc_out,\n",
    "            n_hidden=l_n_hidden,\n",
    "            n_output=l_n_output,\n",
    "        )\n",
    "        self.decoder = DecoderSCVI(\n",
    "            fc_in=decoder_fc_in,\n",
    "            fc_out=decoder_fc_out,\n",
    "            decoder_in=decoder_in,\n",
    "            decoder_out=decoder_out,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (z_encoder): Encoder(\n",
       "    (encoder): FCLayers(\n",
       "      (fc_layers): Sequential(\n",
       "        (0): Linear(in_features=27208, out_features=3, bias=True)\n",
       "        (1): BatchNorm1d(3, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): None\n",
       "        (3): ReLU()\n",
       "        (4): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (mean_encoder): Linear(in_features=3, out_features=50, bias=True)\n",
       "    (var_encoder): Linear(in_features=3, out_features=50, bias=True)\n",
       "  )\n",
       "  (l_encoder): Encoder(\n",
       "    (encoder): FCLayers(\n",
       "      (fc_layers): Sequential(\n",
       "        (0): Linear(in_features=27208, out_features=3, bias=True)\n",
       "        (1): BatchNorm1d(3, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): None\n",
       "        (3): ReLU()\n",
       "        (4): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (mean_encoder): Linear(in_features=3, out_features=1, bias=True)\n",
       "    (var_encoder): Linear(in_features=3, out_features=1, bias=True)\n",
       "  )\n",
       "  (decoder): DecoderSCVI(\n",
       "    (px_decoder): FCLayers(\n",
       "      (fc_layers): Sequential(\n",
       "        (0): Linear(in_features=62, out_features=3, bias=True)\n",
       "        (1): BatchNorm1d(3, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): None\n",
       "        (3): ReLU()\n",
       "        (4): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (px_scale_decoder): Sequential(\n",
       "      (0): Linear(in_features=3, out_features=27208, bias=True)\n",
       "      (1): Softmax(dim=1)\n",
       "    )\n",
       "    (px_r_decoder): Linear(in_features=3, out_features=27208, bias=True)\n",
       "    (px_dropout_decoder): Linear(in_features=3, out_features=27208, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAE(\n",
    "    z_enc_fc_in=27208,\n",
    "    z_enc_fc_out=3,\n",
    "    z_n_hidden=3,\n",
    "    z_n_output=50,\n",
    "    l_enc_fc_in=27208,\n",
    "    l_enc_fc_out=3,\n",
    "    l_n_hidden=3, \n",
    "    l_n_output=1,\n",
    "    decoder_fc_in=62,\n",
    "    decoder_fc_out=3,\n",
    "    decoder_in=3,\n",
    "    decoder_out=27208,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
