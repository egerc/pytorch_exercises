{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Pytorch Experimentation\n",
    "\n",
    "    Developed by: Christian Eger\n",
    "    Würzburg Institute for Systems Immunology, Faculty of Medicine, Julius-Maximilian-Universität Würzburg\n",
    "    Created: 240321\n",
    "    Latest version: 240321\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes in your adata object as well as the category you want to train your data on as well as parameters for defining the datasets sizes and returns two pytorch datasets, one for training and one for testing\n",
    "def obs_to_tensor(adata, category=None, training_size=None, test_size=None):\n",
    "    # This helper function returns a single pytorch dataset from the adata object given a list of observations\n",
    "    def tensors_to_dataset(adata, obs_list, category, label_to_id):\n",
    "        tensors = []\n",
    "        labels = []\n",
    "        for obs in obs_list:\n",
    "            tensors.append(\n",
    "                torch.tensor(\n",
    "                    adata[adata.obs_names == obs].X\n",
    "                    .toarray()\n",
    "                )\n",
    "            )\n",
    "            labels.append(\n",
    "                adata[adata.obs_names == obs].obs[category].iloc[0]\n",
    "            )\n",
    "        tensors = torch.squeeze(torch.stack(tensors))\n",
    "        labels = torch.tensor([label_to_id[label] for label in labels])\n",
    "        return TensorDataset(tensors, labels)\n",
    "\n",
    "    # The purpose of these dictionaries is to encode the values of the desired category as integers\n",
    "    label_to_id = {label: idx for idx, label in enumerate(adata.obs[category].unique())}\n",
    "    id_to_label = {idx: label for label, idx in label_to_id.items()}\n",
    "\n",
    "    # Making sure the total dataset size doesnt exceed the number of observations in the adata object\n",
    "    if test_size + training_size <= adata.shape[0]:\n",
    "        # Randomly sampling from the observations of the adata object\n",
    "        random_obs = np.random.choice(\n",
    "            adata.obs.index,\n",
    "            size=training_size + test_size,\n",
    "            replace=False,\n",
    "        )\n",
    "        # Creating two subsets of the sampled observations for training and testing purposes\n",
    "        random_obs_train = random_obs[:training_size]\n",
    "        random_obs_test = random_obs[-test_size:]\n",
    "\n",
    "        # Creating the datasets using the helper function from the two subset samples\n",
    "        training_data = tensors_to_dataset(adata, random_obs_train, category, label_to_id)\n",
    "        testing_data = tensors_to_dataset(adata, random_obs_test, category, label_to_id)\n",
    "\n",
    "    return(\n",
    "        training_data,\n",
    "        testing_data,\n",
    "        id_to_label,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 97573 × 27208\n",
       "    obs: 'sex', 'age', 'ethnicity', 'PaCO2', 'donor', 'infection', 'disease', 'SMK', 'illumina_stimunr', 'bd_rhapsody', 'n_genes', 'doublet_scores', 'predicted_doublets', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'percent_mt2', 'n_counts', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'condition', 'sample_group', 'IAV_score', 'group', 'Viral_score', 'cell_type', 'cell_states', 'leiden', 'cell_compartment', 'seed_labels', '_scvi_batch', '_scvi_labels', 'C_scANVI'\n",
       "    var: 'mt', 'ribo'\n",
       "    obsm: 'X_scANVI', 'X_scVI', 'X_umap'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "adata = ad.read_h5ad('../data/Marburg_cell_states_locked_scANVI_ctl230901.raw.h5ad')\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "training_data, test_data, labels_map = obs_to_tensor(adata, category='disease', training_size=10000, test_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CUDA devices:\n",
      "  0: NVIDIA RTX 6000 Ada Generation\n",
      "  1: NVIDIA RTX 6000 Ada Generation\n",
      "Using CUDA device: cuda:1\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    num_devices = torch.cuda.device_count()\n",
    "    print(\"Available CUDA devices:\")\n",
    "    for i in range(num_devices):\n",
    "        print(f\"  {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    device = torch.device(\"cuda:1\")  # Change the index if you want to use a different device\n",
    "    print(f\"Using CUDA device: {device}\")\n",
    "    torch.cuda.set_device(device)\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "input_size = adata.shape[1]\n",
    "num_classes = len(labels_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class GeneExpressionClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(GeneExpressionClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = GeneExpressionClassifier(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train loss: 0.001728820150345564, Validation loss: 1.813855800628662\n",
      "Epoch 2/20 - Train loss: 0.001734794738329947, Validation loss: 1.813855800628662\n",
      "Epoch 3/20 - Train loss: 0.001730889684520662, Validation loss: 1.813855800628662\n",
      "Epoch 4/20 - Train loss: 0.0017277152478694915, Validation loss: 1.813855800628662\n",
      "Epoch 5/20 - Train loss: 0.001738824024796486, Validation loss: 1.813855800628662\n",
      "Epoch 6/20 - Train loss: 0.0017314267260953784, Validation loss: 1.813855800628662\n",
      "Epoch 7/20 - Train loss: 0.001733431640639901, Validation loss: 1.813855800628662\n",
      "Epoch 8/20 - Train loss: 0.0017282135169953109, Validation loss: 1.813855800628662\n",
      "Epoch 9/20 - Train loss: 0.0017381363954395055, Validation loss: 1.813855800628662\n",
      "Epoch 10/20 - Train loss: 0.0017278763400390745, Validation loss: 1.813855800628662\n",
      "Epoch 11/20 - Train loss: 0.0017326958841644227, Validation loss: 1.813855800628662\n",
      "Epoch 12/20 - Train loss: 0.0017412024576216936, Validation loss: 1.813855800628662\n",
      "Epoch 13/20 - Train loss: 0.0017313761278986931, Validation loss: 1.813855800628662\n",
      "Epoch 14/20 - Train loss: 0.0017283907873556017, Validation loss: 1.813855800628662\n",
      "Epoch 15/20 - Train loss: 0.0017330198554322124, Validation loss: 1.813855800628662\n",
      "Epoch 16/20 - Train loss: 0.0017316971201449633, Validation loss: 1.813855800628662\n",
      "Epoch 17/20 - Train loss: 0.0017279787374660373, Validation loss: 1.813855800628662\n",
      "Epoch 18/20 - Train loss: 0.0017323208186775447, Validation loss: 1.813855800628662\n",
      "Epoch 19/20 - Train loss: 0.0017289803517982363, Validation loss: 1.813855800628662\n",
      "Epoch 20/20 - Train loss: 0.0017287376886233688, Validation loss: 1.813855800628662\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "model = GeneExpressionClassifier(input_size, num_classes)\n",
    "model.to(device)\n",
    "for i in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for expression, label in train_dataloader:\n",
    "        expression, label = expression.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(expression)\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() / expression.size(0)\n",
    "    train_loss = running_loss / len(train_dataloader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "        # Validation phase\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for expression, label in test_dataloader:\n",
    "            # Move inputs and labels to the device\n",
    "            expression, label = expression.to(device), label.to(device)\n",
    "            outputs = model(expression)\n",
    "            loss = loss_fn(outputs, label)\n",
    "            running_loss += loss.item() * label.size(0)\n",
    "    val_loss = running_loss / len(test_dataloader.dataset)\n",
    "    val_losses.append(val_loss)\n",
    "    print(f\"Epoch {i+1}/{num_epochs} - Train loss: {train_loss}, Validation loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeneExpressionClassifier(\n",
       "  (fc1): Linear(in_features=27208, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.1556,  1.4240], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model(test_data[2][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
