{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undercomplete Autoencoder\n",
    "\n",
    "    Developed by: Christian Eger\n",
    "    Würzburg Institute for Systems Immunology, Faculty of Medicine, Julius-Maximilian-Universität Würzburg\n",
    "    Created: 240327\n",
    "    Latest version: 240327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import anndata as ad\n",
    "import helper\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 97573 × 27208\n",
       "    obs: 'sex', 'age', 'ethnicity', 'PaCO2', 'donor', 'infection', 'disease', 'SMK', 'illumina_stimunr', 'bd_rhapsody', 'n_genes', 'doublet_scores', 'predicted_doublets', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'percent_mt2', 'n_counts', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'condition', 'sample_group', 'IAV_score', 'group', 'Viral_score', 'cell_type', 'cell_states', 'leiden', 'cell_compartment', 'seed_labels', '_scvi_batch', '_scvi_labels', 'C_scANVI'\n",
       "    var: 'mt', 'ribo'\n",
       "    obsm: 'X_scANVI', 'X_scVI', 'X_umap'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata = ad.read_h5ad(\n",
    "    '../data/Marburg_cell_states_locked_scANVI_ctl230901.raw.h5ad'\n",
    ")\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size, testing_size = helper.return_dataset_sizes(adata, 0.8, 0.01)\n",
    "\n",
    "training_data, testing_data = helper.obs_to_tensor(adata, category=None, training_size=training_size, testing_size=testing_size)\n",
    "\n",
    "training_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "testing_dataloader = DataLoader(testing_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The range of values goes from 0 to 18506\n",
      "The number of genes are 27208\n"
     ]
    }
   ],
   "source": [
    "min_val, max_val = helper.return_value_range(training_dataloader)\n",
    "data_size = training_data.shape[1]\n",
    "print(f'The range of values goes from {min_val} to {max_val}\\n'\n",
    "      f'The number of genes are {data_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Undercomplete_Autoencoder(nn.Module):\n",
    "\n",
    "    def __init__(self, data_size):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(data_size, 5000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5000, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 50)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(50, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 5000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5000, data_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CUDA devices:\n",
      "  0: NVIDIA RTX 6000 Ada Generation\n",
      "  1: NVIDIA RTX 6000 Ada Generation\n",
      "Using CUDA device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    num_devices = torch.cuda.device_count()\n",
    "    print(\"Available CUDA devices:\")\n",
    "    for i in range(num_devices):\n",
    "        print(f\"  {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    device = torch.device(\"cuda:1\") \n",
    "    print(f\"Using CUDA device: {device}\")\n",
    "    torch.cuda.set_device(device)\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Undercomplete_Autoencoder(data_size=data_size)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.00001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [03:19<00:00,  5.02it/s]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "training_losses = []\n",
    "model.to(device)\n",
    "for i in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for expression in training_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        expression = expression.to(device)\n",
    "        output = model(expression)\n",
    "        loss = loss_fn(output, expression)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    training_losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f89f40ea3b0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABt8klEQVR4nO3deXwU5f0H8M/m2oSQBEIgB4RLwSuACoogyg1SERVb8IZKrVZBUqRapK1olVD9CSpUqhZBQRprFU9EgkAwAgLhkFuQAAESwhFykWyS3fn9EXYyMzuzO7M7ewQ+b195GWZnZ2cnuzPf+T7f53ksgiAIICIiIgohYcHeASIiIiIlBihEREQUchigEBERUchhgEJEREQhhwEKERERhRwGKERERBRyGKAQERFRyGGAQkRERCEnItg74A2Hw4ETJ04gLi4OFosl2LtDREREOgiCgIqKCqSlpSEszH2OpEkGKCdOnEB6enqwd4OIiIi8UFhYiHbt2rldp0kGKHFxcQAa3mB8fHyQ94aIiIj0KC8vR3p6ungdd6dJBijOZp34+HgGKERERE2MnvIMFskSERFRyGGAQkRERCGHAQoRERGFHAYoREREFHIYoBAREVHIYYBCREREIYcBChEREYUcBihEREQUchigEBERUchhgEJEREQhhwEKERERhRwGKERERBRyGKAEmcMhYNEPBfjp2Llg7woREVHIaJKzGV9MvthxAjO+3AMAODzr9iDvDRERUWhgBiXI9p+sCPYuEBERhRwGKEEmCMHeAyIiotDDAIWIiIhCDgMUIiIiCjkMUIiIiCjkMEAhIiKikMMAhYiIiEIOAxQiIiIKOQxQiIiIKOQwQCEiIqKQwwCFiIiIQg4DFCIiIgo5DFCCTADHuiciIlJigEJEREQhhwEKERERhRwGKERERBRyGKAQERFRyPEpQMnKyoLFYkFmZqa4TBAEzJgxA2lpaYiJicGAAQOwe/du2fNsNhsmTZqEpKQkxMbGYtSoUTh27Jgvu0JEREQXEa8DlM2bN+Odd95B9+7dZctfeeUVzJ49G/PmzcPmzZuRkpKCoUOHoqKiQlwnMzMTy5YtQ3Z2NvLy8lBZWYmRI0fCbrd7/06IiIjoouFVgFJZWYkHHngA7777Llq2bCkuFwQBr7/+OqZPn47Ro0cjIyMD77//Ps6fP4+lS5cCAMrKyrBgwQK89tprGDJkCK677josWbIEO3fuxKpVq8x5V0RERNSkeRWgPPnkk7j99tsxZMgQ2fKCggIUFxdj2LBh4jKr1Yr+/ftj/fr1AID8/HzU1dXJ1klLS0NGRoa4jpLNZkN5ebns56LBYVCIiIhcRBh9QnZ2NrZu3YrNmze7PFZcXAwASE5Oli1PTk7GkSNHxHWioqJkmRfnOs7nK2VlZeGFF14wuqtERETURBnKoBQWFmLy5MlYsmQJoqOjNdezWCyyfwuC4LJMyd0606ZNQ1lZmfhTWFhoZLdDm/vDQkREdEkyFKDk5+ejpKQEPXv2REREBCIiIpCbm4s333wTERERYuZEmQkpKSkRH0tJSUFtbS1KS0s111GyWq2Ij4+X/Vw02MRDRETkwlCAMnjwYOzcuRPbt28Xf3r16oUHHngA27dvR+fOnZGSkoKcnBzxObW1tcjNzUXfvn0BAD179kRkZKRsnaKiIuzatUtch4iIiC5thmpQ4uLikJGRIVsWGxuLVq1aicszMzMxc+ZMdOnSBV26dMHMmTPRrFkz3H///QCAhIQETJgwAU8//TRatWqFxMRETJ06